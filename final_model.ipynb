{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "final_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sergirsanchez/AI-CDT/blob/master/final_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9b74ed7-9e93-428a-aeec-7ea25aa63d74"
      },
      "source": [
        "*Needed imports*"
      ],
      "id": "e9b74ed7-9e93-428a-aeec-7ea25aa63d74"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5516170-90a3-4159-b0d5-8733e0c5cb2b",
        "tags": []
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import shuffle\n",
        "from collections import Counter\n",
        "import itertools\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import string\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ],
      "id": "e5516170-90a3-4159-b0d5-8733e0c5cb2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1470a213-a0f3-493b-b174-e11cf6f9546a"
      },
      "source": [
        "*Function to plot the confusion matrices*"
      ],
      "id": "1470a213-a0f3-493b-b174-e11cf6f9546a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "203f3b57-f8cc-404b-b117-573189bd92a4"
      },
      "source": [
        "def plot_confusion_matrix(cm,target_names, title='Confusion matrix', cmap=None, normalize=True, store = False):\n",
        "  '''Function given by ScikitLearn with a couple of changes on figure size to display a confusion matrix.\n",
        "    \n",
        "  Parameters\n",
        "  ----------\n",
        "  cm : estimator instance\n",
        "      Fitted classifier or a fitted Pipeline in which the last estimator is a classifier.\n",
        "      \n",
        "  target_names : array-like of shape (n_samples,)\n",
        "      Target values.\n",
        "      \n",
        "  title: str, optional\n",
        "      Title of the confusion matrix\n",
        "      \n",
        "  cmpa: str or matplotlib Colormap, optional\n",
        "      Colormap recognized by matplotlib.\n",
        "      \n",
        "  normalize: {‘true’, ‘pred’, ‘all’}, optional\n",
        "      Normalizes confusion matrix over the true (rows), predicted (columns) conditions or all the population. If None, confusion matrix will not be normalized.\n",
        "      \n",
        "  store: boolean, optional\n",
        "    if True stores the cm. Otherwise, just show it\n",
        "    \n",
        "  Returns\n",
        "  -------\n",
        "  plt\n",
        "      Confusion matrix, just if \"Store\" was set to true\n",
        "  '''\n",
        "  FONT_SIZE = 8\n",
        "\n",
        "  accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "  misclass = 1 - accuracy\n",
        "\n",
        "  if cmap is None:\n",
        "      cmap = plt.get_cmap('Blues')\n",
        "\n",
        "  plt.figure(figsize=(4*2, 3*2))    # 8, 6\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "  plt.title(title)\n",
        "  plt.colorbar()\n",
        "\n",
        "  if target_names is not None:\n",
        "      tick_marks = np.arange(len(target_names))\n",
        "      plt.xticks(tick_marks, target_names, rotation=90, fontsize=FONT_SIZE)\n",
        "      plt.yticks(tick_marks, target_names, fontsize=FONT_SIZE)\n",
        "\n",
        "  if normalize:\n",
        "      cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "  thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      if normalize:\n",
        "          plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    fontsize=FONT_SIZE,\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "      else:\n",
        "          plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    fontsize=FONT_SIZE,\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  \n",
        "  if store:\n",
        "      return plt\n",
        "  else:\n",
        "      plt.show()"
      ],
      "id": "203f3b57-f8cc-404b-b117-573189bd92a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78bf8f3f-dd99-474d-b110-2e2bb04b05d0"
      },
      "source": [
        "*Function to create the necessary folders to start the image preprocessing*"
      ],
      "id": "78bf8f3f-dd99-474d-b110-2e2bb04b05d0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6b91b89-7139-4f41-8988-03cd140663c3"
      },
      "source": [
        "def fold_validation(origin_path, augment_passed, augment_failed , folder_name, number_augmented_passed=0, number_augmented_failed=0,  number_of_folds = 5, batch_size=10 , zoom_percentage = 5,\n",
        "                    save_format = 'png', save_prefix = 'augmented', model=tf.keras.applications.vgg16.VGG16(), optimizer=Adam(learning_rate=0.001), optimizer_options = {'learning_rate':0.001}, \n",
        "                    use_stepLR=False, stepLR_values={'drop': 0, 'epochs_drop': 0}, loss='categorical_crossentropy', metrics='accuracy', epochs=10, train_verbosity=2, \n",
        "                    cm_plot_labels=['failed','passed'], cm_title='Confusion matrix', layers_to_remove=1, layers_to_add=[Dense(units=2, activation='softmax')], trainable_layers=-1, file_name='result.txt'):\n",
        "  '''Main function that englobes all the proccess of applying a X fold validation to images given the folder where thety are stored\n",
        "    \n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "\n",
        "  augment_passed : boolean\n",
        "      Indicate if we want to apply or not an image augmentation over the images on \"passed\" subfolder\n",
        "      \n",
        "  augment_failed : boolean\n",
        "      Indicate if we want to apply or not an image augmentation over the images on \"failed\" subfolder\n",
        "      \n",
        "  folder_name : str\n",
        "      Some relevant info obtained through the process will be stored on origin_path/results/folder_name\n",
        "      \n",
        "  number_augmented_passed : int, optional\n",
        "      Number of random images selected from \"passed\" subfolder to apply the data augmentation\n",
        "      \n",
        "  number_augmented_failed : int, optional\n",
        "      Number of random images selected from \"failed\" subfolder to apply the data augmentation\n",
        "      \n",
        "  number_of_folds : int, optional\n",
        "      Numbers of folds to apply\n",
        "      \n",
        "  batch_size : int, optional\n",
        "      \n",
        "  zoom_percentage: int, optional\n",
        "      The augmentation consists on applying a zoom on both axis to the image. This value is the % of zoom to apply - With original dataset a percetage over 5% could make the zoom to crop the clocks borders\n",
        "\n",
        "  save_format : str, optional\n",
        "      Format where the augmented images will be saved\n",
        "      \n",
        "  save_prefix : str, optional\n",
        "      Prefix that the augmented images will have on its name to be differentiated from the original ones\n",
        "      \n",
        "  model : tf.keras.Model, optional\n",
        "      Model to use \n",
        "      \n",
        "  optimizer : tf.keras.optimizers.Optimizer, optional\n",
        "      Optimizer to use. Parameters needed has to be indicated (like, for example, the learning rate). If 'use_stepLR' is set to True, the value 'learning_rate' of this parameter turns into 0\n",
        "      \n",
        "  optimizer_options : dict of int\n",
        "      dictionary with key-value of the optimizer options, just used to store it on the \"results\" file\n",
        "      \n",
        "  use_stepLR : boolean, optional\n",
        "      Indicate if we are going to use scheduled learning rate or not (Learning rate with no static value, it changes through the model epochs)\n",
        "\n",
        "  stepLR_values : dict of int, optional\n",
        "      Object with params needed if we are going to use scheduled learning rate\n",
        "      \n",
        "      initial_lrate : number, optional\n",
        "          Original learning rate\n",
        "          \n",
        "      drop : number, optional\n",
        "          Value between 0 and 1 that shows the decrease of the learning rate each X epochs (ex: 0.1 --> 10%)\n",
        "          \n",
        "      epochs_dopr: number, optional\n",
        "          Number of epochs that indicate how often the the drop is done\n",
        "\n",
        "  loss : str, optional\n",
        "      Indicate the way that model will be sanctioned due to bad predictions\n",
        "      \n",
        "  metrics : list of str, optional\n",
        "      Metrics to be evaluated by the model during training and testing\n",
        "      \n",
        "  epochs : number, optional\n",
        "      Epochs to be execute on each fold\n",
        "      \n",
        "  train_verbosity : int or str, optional\n",
        "      'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 is the most verbose and recommended\n",
        "      \n",
        "  cm_plot_labels : list of str\n",
        "      Labels to be used on X and Y axis of the confusion matrices\n",
        "\n",
        "  cm_title : str\n",
        "      Title of the final confusion matrix\n",
        "      \n",
        "  layers_to_remove : number, optional\n",
        "      The numbers of layers to be removed from the bottom of the model previously indicated\n",
        "      \n",
        "  layers_to_add : list of tk.keras.layers\n",
        "      List with the layers to add at the end of the model previously indicated\n",
        "\n",
        "  trainable_layers: number, optional\n",
        "      Number of trainable layers when the model is created (X layers from the end of the model). If the number is negative, default values will be taken (number of added layers for VGG16 and the last 23 layers for Mobilenet)\n",
        "      \n",
        "  file_name : str, optional\n",
        "      Name of the file that will store info about model parameters on origin_path/results/folder_name\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  plt\n",
        "      Confusion matrix, just if \"Store\" was set to true\n",
        "  '''\n",
        "\n",
        "  os.chdir(origin_path)\n",
        "\n",
        "  if augment_passed == True:\n",
        "      valid_samples = []\n",
        "      path_passed, dirs_passed, files_passed = next(os.walk(f'passed'))\n",
        "\n",
        "      if number_augmented_passed <= len(files_passed):\n",
        "        valid_samples = random.sample(os.listdir(f'passed'),number_augmented_passed)\n",
        "      else:\n",
        "        if number_augmented_passed % len(files_passed) == 0:\n",
        "          for single_image in files_passed:\n",
        "            valid_samples += [single_image] * (number_augmented_passed / len(files_passed))\n",
        "        else:\n",
        "          i = 0\n",
        "          for single_image in files_passed:\n",
        "            if i >= (number_augmented_passed % len(files_passed)):\n",
        "              valid_samples += [single_image] * int(number_augmented_passed / len(files_passed))\n",
        "            else:\n",
        "              valid_samples += [single_image] * int((number_augmented_passed / len(files_passed)) + 1)\n",
        "            i += 1 \n",
        "      \n",
        "      augment_data(origin_path, valid_samples, 'passed', zoom_percentage, save_format, save_prefix)\n",
        " \n",
        "  if augment_failed == True:\n",
        "      valid_samples = []\n",
        "      path_failed, dirs_failed, files_failed = next(os.walk(f'failed'))\n",
        "\n",
        "      if number_augmented_failed <= len(files_failed):\n",
        "        valid_samples = random.sample(os.listdir(f'failed'), number_augmented_failed)\n",
        "      else:\n",
        "        if number_augmented_failed % len(files_failed) == 0:\n",
        "          for single_image in files_failed:\n",
        "            valid_samples += [single_image] * (number_augmented_failed / len(files_failed))\n",
        "        else:\n",
        "          i = 0\n",
        "          for single_image in files_failed:\n",
        "            if i >= (number_augmented_failed % len(files_failed)):\n",
        "              valid_samples += [single_image] * int(number_augmented_failed / len(files_failed))\n",
        "            else:\n",
        "              valid_samples += [single_image] * int((number_augmented_failed / len(files_failed)) + 1)\n",
        "            i += 1 \n",
        "\n",
        "      augment_data(origin_path, valid_samples, 'failed', zoom_percentage, save_format, save_prefix)\n",
        "           \n",
        "  \n",
        "  #Now we create two arrays (one for image names and the other for the scores)\n",
        "  total_image_names, total_scores = create_image_arrays(origin_path)\n",
        "  \n",
        "  #Now let's store the parameters used on a folder\n",
        "  if(os.path.isdir(f'results') == False):\n",
        "      os.mkdir(f'results')\n",
        "  \n",
        "  os.makedirs(f'results/{folder_name}', exist_ok= False)\n",
        "      \n",
        "  #Since there's no method for show the optimizer with the data used, we have to specify it\n",
        "  optimizers_names = ['Adadelta','Adagrad', 'Adam', 'Adamax', 'Ftrl', 'Nadam', 'RMSprop', 'SGD']\n",
        "  real_optimzer_name = ''\n",
        "  for name in optimizers_names:\n",
        "      if str(optimizer).find(name) != -1:\n",
        "          real_optimzer_name = name\n",
        "          break\n",
        "  \n",
        "  last_key = list(optimizer_options.keys())[-1]\n",
        "\n",
        "  optimizer_options_str = ''\n",
        "  for key in optimizer_options:\n",
        "      optimizer_options_str+= f'{key} = {optimizer_options[key]}'\n",
        "\n",
        "      if(key != last_key):\n",
        "          optimizer_options_str +=','\n",
        "      \n",
        "  with open(f'{origin_path}/results/{folder_name}/{file_name}','a') as data_file:\n",
        "      data_file.write('Parameters used:\\n\\n')\n",
        "      data_file.write(f'origin_path: {origin_path}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'augment_passed: {augment_passed}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'augment_failed: {augment_failed}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'number_augmented_passed: {number_augmented_passed}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'number_augmented_failed: {number_augmented_failed}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'zoom_percentage: {zoom_percentage}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'save_format: {save_format}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'save_prefix: {save_prefix}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'model: {model.name}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'optimizer: {real_optimzer_name}({optimizer_options_str})')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'use_stepLR: {use_stepLR}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'stepLR_values: {stepLR_values}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'loss: {loss}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'metrics: {metrics}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'epochs: {epochs}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'train_verbosity: {train_verbosity}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'cm_plot_labels: {cm_plot_labels}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'cm_title: {cm_title}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'layers_to_remove: {layers_to_remove}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write(f'trainable_layers: {trainable_layers}')\n",
        "      data_file.write('\\n\\n')\n",
        "      data_file.write('model with layers_to_add')\n",
        "      data_file.write('\\n\\n')\n",
        "      \n",
        "      \n",
        "  #Finally we apply the X-fold itself\n",
        "  apply_fold_validation(origin_path, folder_name, total_image_names, total_scores, number_of_folds, batch_size, model, optimizer, \n",
        "            use_stepLR, stepLR_values, loss, metrics, epochs, train_verbosity, cm_plot_labels, cm_title, layers_to_remove, layers_to_add, trainable_layers, file_name)\n",
        "  "
      ],
      "id": "f6b91b89-7139-4f41-8988-03cd140663c3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97dadce-1ad1-4045-a56b-2b7d6bf900a7"
      },
      "source": [
        "\"Function to create arrays of image names and results\""
      ],
      "id": "f97dadce-1ad1-4045-a56b-2b7d6bf900a7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "273837f3-5850-4b86-860b-63369d15b957"
      },
      "source": [
        "def create_image_arrays(origin_path):\n",
        "  '''Function to store on a array all the image names and on other array all the scores of the images.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "      \n",
        "  Returns\n",
        "  -------\n",
        "  total_image_names : list of str\n",
        "      Array that contain all the iamge names (first all the images that passed the test, and the all that don't)\n",
        "      \n",
        "  total_scores: list of int\n",
        "      Array that contain 0s and 1s showing if the image passed the test or not\n",
        "  '''\n",
        "  os.chdir(origin_path)\n",
        "\n",
        "  path_passed, dirs_passed, files_passed = next(os.walk(f'{origin_path}/passed'))\n",
        "  path_failed, dirs_failed, files_failed = next(os.walk(f'{origin_path}/failed'))\n",
        "\n",
        "  total_passed = np.ones((len(files_passed),), dtype=int)\n",
        "  total_failed = np.zeros((len(files_failed),), dtype=int)\n",
        "\n",
        "  total_image_names = np.append(files_passed, files_failed)\n",
        "  total_scores = np.append(total_passed, total_failed)   \n",
        "\n",
        "  return total_image_names, total_scores"
      ],
      "id": "273837f3-5850-4b86-860b-63369d15b957",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdca174a-2753-471c-9f58-9d4c8d5b0253"
      },
      "source": [
        "*Function to start the augmentation process on passed and failed tests folder*"
      ],
      "id": "cdca174a-2753-471c-9f58-9d4c8d5b0253"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a07ce95-70f6-4c92-bc54-b4b7bb9f6c6a"
      },
      "source": [
        "def augment_data(origin_path, valid_samples, dst_folder, zoom_percentage = 5, save_format = 'png', save_prefix = 'augmented'):\n",
        "  '''Function in charge of applying the zoom augmentation to the images and store them on the corresponding folder (\"passed\" of \"failed\")\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "    \n",
        "  valid_samples : list of str\n",
        "    List with the image names (some random if the number is below than the number of total images and all of them if the number ia above it) to augment\n",
        "\n",
        "  dst_folder: str\n",
        "      Folder where the images willo go (\"passed\" or \"failed\")\n",
        "      \n",
        "  zoom_percentage: int, optional\n",
        "      The augmentation consists on applying a zoom on both axis to the image. This value is the % of zoom to apply - With original dataset a percetage over 5% could make the zoom to crop the clocks borders\n",
        "      \n",
        "  save_format : str, optional\n",
        "      Format where the augmented images will be saved\n",
        "      \n",
        "  save_prefix : str, optional\n",
        "      Prefix that the augmented images will have on its name to be differentiated from the original ones\n",
        "  '''\n",
        "  total_times_appear = []\n",
        "\n",
        "  set_files = set(valid_samples)\n",
        "\n",
        "  for single_image in set_files:\n",
        "    total_times_appear.append(valid_samples.count(single_image))\n",
        "\n",
        "  for i, single_image in enumerate(set_files):\n",
        "    matrix = []\n",
        "    img = load_img(f'{origin_path}/{dst_folder}/{single_image}')\n",
        "    data = img_to_array(img)\n",
        "    samples = np.expand_dims(data, 0)\n",
        "\n",
        "    for j in range (total_times_appear[i]):\n",
        "      image_zoom = round(random.random()*(round((zoom_percentage/100),2)),4)\n",
        "\n",
        "      while image_zoom in matrix:\n",
        "        image_zoom = round(random.random()*(round((zoom_percentage/100),2)),4)\n",
        "\n",
        "      matrix.append(image_zoom)\n",
        "\n",
        "    for j in range (total_times_appear[i]):\n",
        "      zoom_range = matrix[j]\n",
        "      zoom = ImageDataGenerator(zoom_range=zoom_range, width_shift_range=2, height_shift_range=2)\n",
        "      final_prefix = save_prefix+'_'+''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
        "\n",
        "      augmentImage = zoom.flow(x = samples, save_to_dir=f'{origin_path}/{dst_folder}', save_format=save_format, batch_size=1, save_prefix=final_prefix)\n",
        "      next(augmentImage)\n"
      ],
      "id": "2a07ce95-70f6-4c92-bc54-b4b7bb9f6c6a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b7a60ca-667e-4fb8-90d3-e9ed7281cdfa"
      },
      "source": [
        "*Function to get 5 arrays of images and its results*"
      ],
      "id": "4b7a60ca-667e-4fb8-90d3-e9ed7281cdfa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b6f362a-fea6-4925-82aa-16cedfedef63"
      },
      "source": [
        "def get_segmented_arrays(total_image_names, total_scores, number_of_folds):\n",
        "  '''Function the get X arrays of images and scores (one per fold)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  total_image_names : list of str\n",
        "      Array with the name of all the images\n",
        "\n",
        "  total_scores : list of int\n",
        "      Array with all the scores\n",
        "      \n",
        "  number_of_folds: int\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  result_image_names : list of list of str\n",
        "      Array that contains X arrays with image names\n",
        "      \n",
        "  result_scores : list of list of int\n",
        "      Array that contains X arrays with the scores\n",
        "  '''\n",
        "  # First of all, we shuffle the images\n",
        "  total_image_names_shuffleled, total_scores_shuffleled = shuffle(total_image_names, total_scores)\n",
        "  \n",
        "  result_image_names = []\n",
        "  result_scores = []\n",
        "  \n",
        "  for i in range (0, number_of_folds):\n",
        "      result_image_names.append([])\n",
        "      result_scores.append([])\n",
        "      \n",
        "  i = 0\n",
        "  \n",
        "  for singleImage in total_image_names_shuffleled:\n",
        "      currentIndex = i%number_of_folds\n",
        "      result_image_names[currentIndex].append(singleImage)\n",
        "      i+=1\n",
        "      \n",
        "  i = 0\n",
        "  \n",
        "  for singleScore in total_scores_shuffleled:\n",
        "      currentIndex = i%number_of_folds\n",
        "      result_scores[currentIndex].append(singleScore)\n",
        "      i+=1\n",
        "          \n",
        "  result_image_names = np.array(result_image_names, dtype=object)\n",
        "  result_scores = np.array(result_scores, dtype=object)\n",
        "\n",
        "  return result_image_names, result_scores\n"
      ],
      "id": "0b6f362a-fea6-4925-82aa-16cedfedef63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "735ab65a-6ff9-4f0f-a897-a4a504ffd90e"
      },
      "source": [
        "*Function to store the images on test, training and validation folder*"
      ],
      "id": "735ab65a-6ff9-4f0f-a897-a4a504ffd90e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f52817f7-4efe-4734-a231-ab5da38c4846"
      },
      "source": [
        "def store_images(origin_path,train_validation_images, train_validation_scores, test_images, test_scores, number_of_folds):\n",
        "  '''Function that create 3 folders: training, validation and test, each of them with passed and failed subfolder, and store \n",
        "   the images on the corresponding folder per each epoch. This folder structure is the used by the machine learning algorithm\n",
        "   to train and test the data\n",
        "   \n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "      \n",
        "  train_validation_images : list of list of str\n",
        "      Array that contains X arrays with image names that will be used on training and validation\n",
        "      \n",
        "  train_validation_scores : list of list of int\n",
        "      Array that contains X arrays with the scores that will be used on training and validation\n",
        "      \n",
        "  test_images : list of list of str\n",
        "      Array that contains X arrays with image names that will be used on test\n",
        "      \n",
        "  test_scores : list of list of int\n",
        "      Array that contains X arrays with the scores that will be used on test\n",
        "      \n",
        "  number_of_folds: int\n",
        "      \n",
        "  '''\n",
        "  os.chdir(origin_path)\n",
        "  \n",
        "  if(os.path.isdir(f'train') == False & os.path.isdir(f'test') == False & os.path.isdir(f'validation') == False):\n",
        "      os.mkdir(f'train') \n",
        "      os.mkdir(f'train/passed') \n",
        "      os.mkdir(f'train/failed')\n",
        "      os.mkdir(f'validation') \n",
        "      os.mkdir(f'validation/passed') \n",
        "      os.mkdir(f'validation/failed')\n",
        "      os.mkdir(f'test') \n",
        "      os.mkdir(f'test/passed') \n",
        "      os.mkdir(f'test/failed')\n",
        "      \n",
        "  if(os.path.isdir(f'train') == True & os.path.isdir(f'test') == True & os.path.isdir(f'validation') == True):\n",
        "      if ((len(os.listdir(f'train/passed')) == 0 & len(os.listdir(f'train/failed')) == 0) & (len(os.listdir(f'test/passed')) == 0 & len(os.listdir(f'test/failed')) == 0)\n",
        "          & (len(os.listdir(f'validation/passed')) == 0 & len(os.listdir(f'validation/failed')) == 0)):\n",
        "          \n",
        "          # Clean folders each time or it will be done just the first time\n",
        "          clean_folders(origin_path,'train')\n",
        "          clean_folders(origin_path,'validation')        \n",
        "          clean_folders(origin_path,'test')\n",
        "          \n",
        "          number_of_validations = math.floor(number_of_folds/5)\n",
        "          validation_indices = []\n",
        "          validation_images = []\n",
        "          validation_scores = []\n",
        "          train_validation_images_copy = train_validation_images\n",
        "          train_validation_scores_copy = train_validation_scores\n",
        "\n",
        "          for i in range(0, number_of_validations):\n",
        "              current_index = random.randint(0, number_of_folds-2)\n",
        "\n",
        "              while(current_index in validation_indices):\n",
        "                  current_index = random.randint(0, number_of_folds-2)\n",
        "              \n",
        "              validation_indices.append(current_index)\n",
        "              \n",
        "          validation_indices.sort(reverse=True)\n",
        "\n",
        "          for i in range (0, len(validation_indices)):\n",
        "              validation_images.append(train_validation_images[validation_indices[i]])\n",
        "              validation_scores.append(train_validation_scores[validation_indices[i]])\n",
        "          \n",
        "          for number in validation_indices:\n",
        "              train_validation_images_copy = np.delete(train_validation_images_copy, number, 0)\n",
        "              train_validation_scores_copy = np.delete(train_validation_scores_copy, number, 0)\n",
        "          \n",
        "          validation_images = np.array(validation_images).flatten()\n",
        "          validation_scores = np.array(validation_scores).flatten()\n",
        "          train_images = np.hstack(train_validation_images_copy)\n",
        "          train_scores = np.hstack(train_validation_scores_copy)\n",
        "          \n",
        "          for i in range(len(train_images)):\n",
        "              if(train_scores[i] == 0):\n",
        "                  shutil.copy(f'{origin_path}/failed/{train_images[i]}', f'train/failed')\n",
        "              else:\n",
        "                  shutil.copy(f'{origin_path}/passed/{train_images[i]}', f'train/passed')\n",
        "\n",
        "          for i in range(len(validation_images)):\n",
        "              if(validation_scores[i] == 0):\n",
        "                  shutil.copy(f'{origin_path}/failed/{validation_images[i]}', f'validation/failed')\n",
        "              else:\n",
        "                  shutil.copy(f'{origin_path}/passed/{validation_images[i]}', f'validation/passed')\n",
        "\n",
        "          for i in range(len(test_images)):\n",
        "              if(test_scores[i] == 0):\n",
        "                  shutil.copy(f'{origin_path}/failed/{test_images[i]}', f'test/failed')\n",
        "              else:\n",
        "                  shutil.copy(f'{origin_path}/passed/{test_images[i]}', f'test/passed')"
      ],
      "id": "f52817f7-4efe-4734-a231-ab5da38c4846",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70ab89a3-30ca-4dc1-974d-d00d3da57060"
      },
      "source": [
        "**Function to create the model**"
      ],
      "id": "70ab89a3-30ca-4dc1-974d-d00d3da57060"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191b2273-6444-46f1-adfb-f3b8f36fe1b0"
      },
      "source": [
        "def create_model(origin_path, folder_name, file_name, model, optimizer, loss, metrics, layers_to_remove, layers_to_add, trainable_layers):\n",
        "  '''Function where the model with the layers to add and delete is created and compiled\n",
        "  \n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path: str\n",
        "      Origin path where the \"passed\" and \"failed\" fodler are\n",
        "  \n",
        "  folder_name: str\n",
        "      Name of the folder where all the results for this execution are stored\n",
        "\n",
        "  file_name: str\n",
        "      Name of the file where the summary with all the variables are done\n",
        "\n",
        "  model : tf.keras.Model\n",
        "      Model to use \n",
        "      \n",
        "  optimizer : tf.keras.optimizers.Optimizer\n",
        "      Optimizer to use. Parameters needed has to be indicated (like, for example, the learning rate). If 'use_stepLR' is set to True, the value 'learning_rate' of this parameter turns into 0\n",
        "      \n",
        "  loss : str, optional\n",
        "      Indicate the way that model will be sanctioned due to bad predictions\n",
        "      \n",
        "  metrics : list of str, optional\n",
        "      Metrics to be evaluated by the model during training and testing\n",
        "      \n",
        "  layers_to_remove : number, optional\n",
        "      The numbers of layers to be removed from the bottom of the model previously indicated\n",
        "      \n",
        "  layers_to_add : list of tk.keras.layers\n",
        "      List with the layers to add at the end of the model previously indicated\n",
        "\n",
        "  trainable_layers: number, optional\n",
        "      Number of trainable layers when the model is created (X layers from the end of the model). If the number is negative, default values will be taken (number of added layers for VGG16 and the last 23 layers for Mobilenet)\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  new_model : tf.keras.Model\n",
        "      Model generated and compiled\n",
        "  '''\n",
        "\n",
        "  if 'vgg16' in model.name:\n",
        "    vgg16_model = model\n",
        "    \n",
        "    # We maintain the whole model except from the last level, and we make that the levels already trained by default not trainable on this model\n",
        "    new_model = Sequential()\n",
        "\n",
        "    for layer in vgg16_model.layers[:-layers_to_remove]:\n",
        "        new_model.add(layer)\n",
        "\n",
        "    trainable_layers = trainable_layers if trainable_layers >=0 else len(new_model.layers)\n",
        "\n",
        "    for layer in layers_to_add:\n",
        "        new_model.add(layer)\n",
        "\n",
        "  elif 'mobilenet' in model.name:\n",
        "    original_layers = model.layers[-(layers_to_remove+1)].output\n",
        "    \n",
        "    for single_layer in layers_to_add:\n",
        "      original_layers = single_layer(original_layers)\n",
        "\n",
        "    new_model = Model(inputs = model.input, outputs = original_layers)\n",
        "\n",
        "    trainable_layers = trainable_layers if trainable_layers >=0 else 23\n",
        "\n",
        "    new_model.summary() \n",
        "    \n",
        "  for layer in new_model.layers[:-(trainable_layers+1)]:\n",
        "    layer.trainable = False \n",
        "      \n",
        "  #Last, we compile the model specifying the parameters\n",
        "  new_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])\n",
        "\n",
        "  with open(f'{origin_path}/results/{folder_name}/{file_name}', 'a') as data_file:\n",
        "    with redirect_stdout(data_file):\n",
        "      new_model.summary()\n",
        "\n",
        "  return new_model\n",
        "    "
      ],
      "id": "191b2273-6444-46f1-adfb-f3b8f36fe1b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "538891ca-0fa9-45e6-89f1-cfabee595eb9"
      },
      "source": [
        "Function to create the learning rate scheduler if needed"
      ],
      "id": "538891ca-0fa9-45e6-89f1-cfabee595eb9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "310e87fc-2ee0-4ad7-aba7-130c30d6fd21"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  '''Function that given a epoch returns the learning rate (only for scheduled learning rate, where it varies through epochs)\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  epoch : int\n",
        "      Current epoch\n",
        "  lr : int\n",
        "      Current learning rate\n",
        "  Returns\n",
        "  -------\n",
        "  lr : double\n",
        "      Learning rate depending on the epoch\n",
        "  '''\n",
        "  print('the learning rate: ', lr, ' and the epoch: ', epoch)\n",
        "  if ((epoch+1) % stepLR_values['epochs_drop'] == 0) & (epoch != 0):\n",
        "    return lr * tf.math.exp(-stepLR_values['drop'])\n",
        "  else:\n",
        "    if epoch == 0:\n",
        "      return optimizer_options['learning_rate'] if optimizer_options['learning_rate'] else 0.001\n",
        "    else:\n",
        "      return lr"
      ],
      "id": "310e87fc-2ee0-4ad7-aba7-130c30d6fd21",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "581e0e21-1cbe-4122-a0ec-c702622d4568"
      },
      "source": [
        "*function to train the model*"
      ],
      "id": "581e0e21-1cbe-4122-a0ec-c702622d4568"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "910c268f-8f6d-4608-97a1-3df649cbf114"
      },
      "source": [
        "def train_model(model, train_batches, validation_batches, test_batches, epochs, use_stepLR, stepLR_values, train_verbosity = 2):\n",
        "  '''Function where given the model and the data needed, it trains and return the predictions for the test data\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  model : tf.keras.Model\n",
        "      Model to use \n",
        "      \n",
        "  train_batches : tf.keras.preprocessing.image.ImageDataGenerator\n",
        "      Batches of tensor image data with real-time data augmentation (used for training)\n",
        "      \n",
        "  validation_batches : tf.keras.preprocessing.image.ImageDataGenerator\n",
        "      Batches of tensor image data with real-time data augmentation (used for validation)\n",
        "      \n",
        "  test_batches : tf.keras.preprocessing.image.ImageDataGenerator\n",
        "      Batches of tensor image data with real-time data augmentation (used for testing)\n",
        "\n",
        "  epochs : number, optional\n",
        "      Epochs to be execute on each fold\n",
        "      \n",
        "  use_stepLR : boolean, optional\n",
        "      Indicate if we are going to use scheduled learning rate or not (Learning rate with no static value, it changes through the model epochs)\n",
        "\n",
        "  stepLR_values : dict of int, optional\n",
        "      Object with params needed if we are going to use scheduled learning rate\n",
        "      \n",
        "  train_verbosity : int or str, optional\n",
        "      'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 is the most verbose and recommended\n",
        "      \n",
        "  Returns\n",
        "  ----------\n",
        "  predictions : list of int\n",
        "      Numpy array(s) of predictions\n",
        "  '''\n",
        "  #Time to start training the model\n",
        "  if(use_stepLR == True):\n",
        "      \n",
        "      callback = LearningRateScheduler(scheduler)\n",
        "      # Fit the model\n",
        "      model.fit(x=train_batches, validation_data=validation_batches, epochs=epochs, callbacks=[callback], verbose=train_verbosity)\n",
        "  else:\n",
        "      model.fit(x=train_batches, validation_data=validation_batches, epochs=epochs, verbose=train_verbosity)\n",
        "      \n",
        "  #Once training, let's apply what it learned to the test model\n",
        "  predictions = model.predict(x=test_batches, verbose=0)\n",
        "  \n",
        "  return predictions"
      ],
      "id": "910c268f-8f6d-4608-97a1-3df649cbf114",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c920944-0b18-42f4-870f-b052eab26010"
      },
      "source": [
        "*Function to get the confusion matrix*"
      ],
      "id": "5c920944-0b18-42f4-870f-b052eab26010"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbf6d48b-a387-4250-899c-3039d4ed8936"
      },
      "source": [
        "def get_cm(true_results, predicted_results):\n",
        "  '''Function that given a real and a predicted array generate a confusion matrix object\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  true_results : list of int\n",
        "      Array with true scores\n",
        "\n",
        "  predicted_results : list of int\n",
        "      Array with predicted scores from the model\n",
        "      \n",
        "  Returns\n",
        "  -------\n",
        "  A sklearn.metrics.confusion_matrix\n",
        "  '''\n",
        "  return confusion_matrix(y_true=true_results, y_pred=predicted_results)"
      ],
      "id": "bbf6d48b-a387-4250-899c-3039d4ed8936",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c33ca024-3f16-4a62-96b7-e8dc39713255"
      },
      "source": [
        "*Function to clean test, validation and training folders*"
      ],
      "id": "c33ca024-3f16-4a62-96b7-e8dc39713255"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32d46b42-9808-4b88-b098-52f48f10fab4"
      },
      "source": [
        "def clean_folders(origin_path, folder):\n",
        "  '''Function that between folds clean the passed and failed subfolders of training, validation and test folders before introduce the images from the new folder\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "      \n",
        "  folder : str\n",
        "      Folder where the subfolders have to be removed (training, validation or test)\n",
        "\n",
        "  '''\n",
        "  os.chdir(origin_path)\n",
        "  \n",
        "  dir_passed = f'{folder}/passed'\n",
        "  dir_failed = f'{folder}/failed'\n",
        "  \n",
        "  for f in os.listdir(dir_passed):\n",
        "      os.remove(os.path.join(dir_passed, f))\n",
        "  for f in os.listdir(dir_failed):\n",
        "      os.remove(os.path.join(dir_failed, f))"
      ],
      "id": "32d46b42-9808-4b88-b098-52f48f10fab4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c11f3336-eff2-4e4a-95c3-ca5935498010"
      },
      "source": [
        "*Function to get the true and predicted numpy arrays from the folder to generate confusion matrices*"
      ],
      "id": "c11f3336-eff2-4e4a-95c3-ca5935498010"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d134c9e6-b71a-4dbf-b999-0b68e6023391"
      },
      "source": [
        "def get_numpy_arrays_to_cm (origin_path, folder_name, number_of_folds):\n",
        "  '''Function to get from the folder of true and predicted results the arrays to generate confusion matrices.\n",
        "   Ex:\n",
        "       result = get_numpy_arrays_to_cm(origin_path, folder_name, number_of_folds)\n",
        "       cm = get_cm(result[0], result[1])\n",
        "       plot_confusion_matrix(cm=cm, target_names=cm_plot_labels, normalize=False, title=f'Final {cm_title}')\n",
        "       \n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "      \n",
        "  folder_name : str\n",
        "      Some relevant info obtained through the process will be stored on origin_path/results/folder_name\n",
        "      \n",
        "  number_of_folds : int, optional\n",
        "      Numbers of folds to apply\n",
        "      \n",
        "  Returns\n",
        "  -------\n",
        "  result : list of list of int\n",
        "      The array with arrays of true and predicted results. The even elements are the true results, and the odd ones the predicted results\n",
        "      \n",
        "      Ex:\n",
        "          result[0] --> True results for fold 1\n",
        "          result[1] --> Predicted results for fold 1\n",
        "          result[2] --> True results for fold 2\n",
        "          ...\n",
        "  '''\n",
        "  result = []\n",
        "  \n",
        "  with open(f'{origin_path}/results/{folder_name}/true_and_predicted_results.npy','rb') as data_file:\n",
        "      for i in range(number_of_folds*2):\n",
        "          current_array = np.load(data_file)\n",
        "          result.append(current_array)\n",
        "          \n",
        "  return result\n",
        "\n"
      ],
      "id": "d134c9e6-b71a-4dbf-b999-0b68e6023391",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d1335e2-7913-4b2b-87b9-adb9283aea95"
      },
      "source": [
        "*Function to do the X-fold validation*"
      ],
      "id": "2d1335e2-7913-4b2b-87b9-adb9283aea95"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5a4e638-8e53-418e-8258-5d37a18b028a",
        "tags": []
      },
      "source": [
        "def apply_fold_validation(origin_path, folder_name, total_image_names, total_scores, number_of_folds = 5, batch_size = 10, model = tf.keras.applications.vgg16.VGG16(), optimizer = Adam(learning_rate=0.001) , use_stepLR = False,\n",
        "              stepLR_values = {'drop': 0, 'epochs_drop': 0}, loss='categorical_crossentropy', metrics='accuracy', epochs=10, train_verbosity=2, cm_plot_labels=['failed','passed'],\n",
        "              cm_title='Confusion matrix', layers_to_remove=1, layers_to_add=[Dense(units=2, activation='softmax')], trainable_layers=-1, file_name='result.txt'):\n",
        "  \n",
        "  '''Function where the operations per each fold are done. Also it generate some data saved on \"results\" folder, like the models per each epoch or an image of the confusion matrix per fold and the final one\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  origin_path : str\n",
        "      Origin folder to use, where the images are stores. The folder has to be at least two subfolders: One \"passed\", with the images that pass the test, and other \"failed\", with tests that don't\n",
        "      \n",
        "  folder_name : str\n",
        "      Some relevant info obtained through the process will be stored on origin_path/results/folder_name\n",
        "\n",
        "  total_image_names : list of str\n",
        "      Array that contain all the iamge names (first all the images that passed the test, and the all that don't)\n",
        "      \n",
        "  total_scores: list of int\n",
        "      Array that contain 0s and 1s showing if the image passed the test or not\n",
        "      \n",
        "  number_of_folds : int, optional\n",
        "      Numbers of folds to apply\n",
        "      \n",
        "  batch_size : int, optional\n",
        "      \n",
        "  model : tf.keras.Model, optional\n",
        "      Model to use \n",
        "      \n",
        "  optimizer : tf.keras.optimizers.Optimizer, optional\n",
        "      Optimizer to use. Parameters needed has to be indicated (like, for example, the learning rate). If 'use_stepLR' is set to True, the value 'learning_rate' of this parameter turns into 0\n",
        "      \n",
        "  use_stepLR : boolean, optional\n",
        "      Indicate if we are going to use scheduled learning rate or not (Learning rate with no static value, it changes through the model epochs)\n",
        "\n",
        "  stepLR_values : dict of int, optional\n",
        "      Object with params needed if we are going to use scheduled learning rate\n",
        "      \n",
        "      initial_lrate : number, optional\n",
        "          Original learning rate\n",
        "          \n",
        "      drop : number, optional\n",
        "          Value between 0 and 1 that shows the decrease of the learning rate each X epochs (ex: 0.1 --> 10%)\n",
        "          \n",
        "      epochs_dopr: number, optional\n",
        "          Number of epochs that indicate how often the the drop is done\n",
        "\n",
        "  loss : str, optional\n",
        "      Indicate the way that model will be sanctioned due to bad predictions\n",
        "      \n",
        "  metrics : list of str, optional\n",
        "      Metrics to be evaluated by the model during training and testing\n",
        "      \n",
        "  epochs : number, optional\n",
        "      Epochs to be execute on each fold\n",
        "      \n",
        "  train_verbosity : int or str, optional\n",
        "      'auto', 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch. 'auto' defaults to 1 for most cases, but 2 is the most verbose and recommended\n",
        "      \n",
        "  cm_plot_labels : list of str, optional\n",
        "      Labels to be used on X and Y axis of the confusion matrices\n",
        "\n",
        "  cm_title : str, optional\n",
        "      Title of the final confusion matrix\n",
        "      \n",
        "  layers_to_remove : number, optional\n",
        "      The numbers of layers to be removed from the bottom of the model previously indicated\n",
        "      \n",
        "  layers_to_add : list of tk.keras.layers, optional\n",
        "      List with the layers to add at the end of the model previously indicated\n",
        "\n",
        "  trainable_layers: number, optional\n",
        "      Number of trainable layers when the model is created (X layers from the end of the model). If the number is negative, default values will be taken (number of added layers for VGG16 and the last 23 layers for Mobilenet)\n",
        "      \n",
        "  file_name : str, optional\n",
        "      Name of the file that will store info about model parameters on origin_path/results/folder_name\n",
        "\n",
        "  '''\n",
        "  # Here we declare the path of the necessary folders, define the model and the array that will store the confusion matrices\n",
        "  train_path = f'{origin_path}/train'\n",
        "  valid_path = f'{origin_path}/validation'\n",
        "  test_path = f'{origin_path}/test'\n",
        "  \n",
        "  model = create_model(origin_path, folder_name, file_name, model, optimizer, loss, metrics, layers_to_remove, layers_to_add, trainable_layers)\n",
        "  \n",
        "  true_results = []\n",
        "  predicted_results = []\n",
        "  \n",
        "  if(os.path.isdir(f'results/{folder_name}/models') == False):\n",
        "      os.mkdir(f'results/{folder_name}/models')\n",
        "      \n",
        "  if(os.path.isdir(f'results/{folder_name}/confusion_matrices') == False):\n",
        "      os.mkdir(f'results/{folder_name}/confusion_matrices')\n",
        "      \n",
        "  # Now we split the full array of image names and scores into X arrays, to implement de X-fold\n",
        "  image_names_arrays, scores_arrays = get_segmented_arrays(total_image_names, total_scores, number_of_folds)\n",
        "  \n",
        "  for i in range(number_of_folds):\n",
        "      print('\\n\\n')\n",
        "      print(F'######################## START OF FOLD {i+1} ########################')\n",
        "      print('\\n')\n",
        "\n",
        "      if number_of_folds > 1 :\n",
        "        test_images = image_names_arrays[i]\n",
        "        test_scores = scores_arrays[i]\n",
        "        \n",
        "        train_validation_images = np.delete(image_names_arrays,i,0)\n",
        "        train_validation_scores = np.delete(scores_arrays,i,0)  \n",
        "\n",
        "      else:\n",
        "        image_names_arrays = image_names_arrays.flatten()\n",
        "        scores_arrays = scores_arrays.flatten()\n",
        "\n",
        "        mid_image_names_arrays = int(len(image_names_arrays)/2)\n",
        "        mid_scores_arrays = int(len(scores_arrays)/2)\n",
        "\n",
        "        test_images = image_names_arrays[ : mid_image_names_arrays]\n",
        "        test_scores = scores_arrays[ : mid_scores_arrays]\n",
        "        \n",
        "        train_validation_images = image_names_arrays[mid_image_names_arrays : ]\n",
        "        train_validation_scores = scores_arrays[mid_scores_arrays : ]\n",
        "      \n",
        "      # Once we have the test and train&validation arrays per each fold, let's introduce each one on its folder (+/- 20% validation / +/- 80% test to make it easier)\n",
        "      store_images(origin_path,train_validation_images, train_validation_scores, test_images, test_scores, number_of_folds)\n",
        "      \n",
        "        # Added the images to their corresponding folder, let's create the tensors\n",
        "      train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(224,224), classes=cm_plot_labels, batch_size= batch_size)\n",
        "      validation_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=valid_path, target_size=(224,224), classes=cm_plot_labels, batch_size= batch_size)\n",
        "      test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=(224,224), classes=cm_plot_labels, batch_size= batch_size, shuffle=False)\n",
        "      \n",
        "      #Time to train the model\n",
        "      predictions = train_model(model,train_batches, validation_batches, test_batches, epochs, use_stepLR, stepLR_values, train_verbosity)\n",
        "      \n",
        "      #We store the models\n",
        "          \n",
        "      model.save(f'results/{folder_name}/models/{model.name}-fold-{i+1}.h5')\n",
        "      \n",
        "      #Store the values on arrays to display later a confusion matrix\n",
        "      current_true = test_batches.classes\n",
        "      current_predicted = np.argmax(predictions, axis=-1)\n",
        "      \n",
        "      true_results.append(current_true)\n",
        "      predicted_results.append(current_predicted)\n",
        "      \n",
        "      with open(f'{origin_path}/results/{folder_name}/true_and_predicted_results.npy','ab') as data_file:\n",
        "          np.save(data_file, np.array(current_true))\n",
        "          np.save(data_file, current_predicted)\n",
        "\n",
        "                  \n",
        "      # Clean folders each time or it will be done just the first time\n",
        "      clean_folders(origin_path,'train')\n",
        "      clean_folders(origin_path,'validation')        \n",
        "      clean_folders(origin_path,'test')\n",
        "      \n",
        "      #Then, let's store image of the fold confusion matrix\n",
        "      fold_cm = get_cm(test_batches.classes, np.argmax(predictions, axis=-1).flatten())\n",
        "      plot_fold_cm = plot_confusion_matrix(cm=fold_cm, target_names=cm_plot_labels, normalize=False, title=f'{cm_title} on fold {i+1}', store=True)\n",
        "      plot_fold_cm.savefig(f'results/{folder_name}/confusion_matrices/matrix_fold_{i+1}.png')\n",
        "    \n",
        "  #Finally, we delete the training, validation and test folders & generate the cm and display it\n",
        "  shutil.rmtree(f'train')\n",
        "  shutil.rmtree(f'test')\n",
        "  shutil.rmtree(f'validation')\n",
        "\n",
        "  true_results = np.array(true_results)\n",
        "  final_true = true_results.flatten()\n",
        "  \n",
        "  predicted_results = np.array(predicted_results)\n",
        "  final_predicted = predicted_results.flatten()\n",
        "      \n",
        "  print('\\n\\n')\n",
        "  print(F'######################## CONFUSION MATRIX ########################')\n",
        "  print('\\n')\n",
        "  cm = get_cm(np.concatenate(true_results), np.concatenate(predicted_results)) \n",
        "  final_matrix = plot_confusion_matrix(cm=cm, target_names=cm_plot_labels, normalize=False, title=f'Final {cm_title}', store=True)\n",
        "  final_matrix.savefig(f'results/{folder_name}/confusion_matrices/final_matrix.png')\n",
        "\n",
        "  right_predictions = 0\n",
        "\n",
        "  for i in range(len(final_true)):\n",
        "    if final_true[i] == final_predicted[i]:\n",
        "      right_predictions += 1 \n",
        "\n",
        "  final_accuracy = round(((right_predictions)*100) / len(final_true),2)\n",
        "\n",
        "  with open(f'{origin_path}/results/{folder_name}/{file_name}','a') as data_file:\n",
        "    data_file.write('#'*50)\n",
        "    data_file.write(f' FINAL ACCURACY:{final_accuracy}% ')\n",
        "    data_file.write('#'*50)\n",
        "            "
      ],
      "id": "f5a4e638-8e53-418e-8258-5d37a18b028a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7QZL6fTiqJA"
      },
      "source": [
        "##PARAMETERS##"
      ],
      "id": "k7QZL6fTiqJA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc771766-d10e-4def-b0f9-441c6e322943"
      },
      "source": [
        "################################################################ PARAMS FOR VGG16 ################################################################\n",
        "#Path and augmentation variables\n",
        "origin_path = '.'\n",
        "augment_passed = False\n",
        "augment_failed = False\n",
        "number_augmented_passed = 0\n",
        "number_augmented_failed = 0\n",
        "zoom_percentage = 5\n",
        "save_format = 'jpg'\n",
        "save_prefix = 'augmented'\n",
        "\n",
        "#Model variables\n",
        "number_of_folds = 5\n",
        "batch_size = 4 \n",
        "model=tf.keras.applications.vgg16.VGG16()\n",
        "optimizer_options = {'learning_rate':0.001}\n",
        "optimizer=SGD(learning_rate=0.001)\n",
        "loss='categorical_crossentropy'\n",
        "metrics='accuracy'\n",
        "epochs = 30\n",
        "train_verbosity = 2\n",
        "cm_plot_labels = ['failed','passed']\n",
        "cm_title = 'Confusion matrix'\n",
        "layers_to_remove = 4\n",
        "trainable_layers = -1 #A positive number will say the number of trainable layers; a negative one will take default values (number of added layers for VGG16 and 23 last layers for Mobilenet)\n",
        "layers_to_add = [\n",
        "                 Flatten(),\n",
        "                 Dense(input_shape=(25088,), units=12000, activation='relu'),\n",
        "                 Dropout(0.25),\n",
        "                 Dense(units=6000, activation='relu'),\n",
        "                 Dropout(0.25),\n",
        "                 Dense(units=1000, activation='relu'),\n",
        "                 Dropout(0.25),\n",
        "                 Dense(units=500, activation='relu'),\n",
        "                 Dropout(0.25),\n",
        "                 Dense(units=2, activation='softmax')\n",
        "]\n",
        "\n",
        "use_stepLR = True \n",
        "stepLR_values={'drop': 0.1, 'epochs_drop': 7}\n",
        "\n",
        "#Other variables\n",
        "folder_name = 'vgg16_full_dataset_softmax_first_time'\n",
        "file_name = 'result.txt'"
      ],
      "id": "fc771766-d10e-4def-b0f9-441c6e322943",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnAhnNtLMld7"
      },
      "source": [
        "################################################################ PARAMS FOR MOBILENET ################################################################\n",
        "#Path and augmentation variables\n",
        "# origin_path = '.'\n",
        "# augment_passed = False\n",
        "# augment_failed = False\n",
        "# number_augmented_passed = 0\n",
        "# number_augmented_failed = 0\n",
        "# zoom_percentage = 5\n",
        "# save_format = 'jpg'\n",
        "# save_prefix = 'augmented'\n",
        "\n",
        "# #Model variables\n",
        "# number_of_folds = 1\n",
        "# batch_size = 4 \n",
        "# model=tf.keras.applications.mobilenet.MobileNet()\n",
        "# optimizer_options = {'learning_rate':0.001}\n",
        "# optimizer=Adam(learning_rate=0.001)\n",
        "# loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "# epochs = 30\n",
        "# train_verbosity = 2\n",
        "# cm_plot_labels = ['failed','passed']\n",
        "# cm_title = 'Confusion matrix'\n",
        "# layers_to_remove = 4\n",
        "# trainable_layers = -1 #A positive number will say the number of trainable layers; a negative one will take default values (number of added layers for VGG16 and 23 last layers for Mobilenet)\n",
        "# layers_to_add = [\n",
        "#                  Flatten(),\n",
        "#                  Dense(input_shape=(25088,), units=12000, activation='relu'),\n",
        "#                  Dropout(0.25),\n",
        "#                  Dense(units=6000, activation='relu'),\n",
        "#                  Dropout(0.25),\n",
        "#                  Dense(units=1000, activation='relu'),\n",
        "#                  Dropout(0.25),\n",
        "#                  Dense(units=500, activation='relu'),\n",
        "#                  Dropout(0.25),\n",
        "#                  Dense(units=2, activation='relu')\n",
        "# ]\n",
        "\n",
        "# use_stepLR = False #If it's true then the lr of the optimizer will be discarded\n",
        "# #drop = 0.1 #How much the LR decrase (ex: 0.1 === 10%)\n",
        "# #epochs_drop = 7.0 #How many epochs the LR decrease\n",
        "\n",
        "# stepLR_values={}\n",
        "\n",
        "# #Other variables\n",
        "# folder_name = 'mobilenet_prueba'\n",
        "# file_name = 'result.txt'"
      ],
      "id": "SnAhnNtLMld7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "EEZ2MK4oC9gd",
        "outputId": "e4fcfc9d-3ec3-4afc-869a-c6e62073f3a7"
      },
      "source": [
        "fold_validation(\n",
        "    origin_path = origin_path,\n",
        "    augment_passed = augment_passed,\n",
        "    augment_failed = augment_failed,\n",
        "    folder_name = folder_name,\n",
        "    number_augmented_passed = number_augmented_passed,\n",
        "    number_augmented_failed = number_augmented_failed,\n",
        "    number_of_folds = number_of_folds,\n",
        "    batch_size = batch_size,\n",
        "    zoom_percentage = zoom_percentage,\n",
        "    save_format = save_format,\n",
        "    save_prefix = save_prefix,\n",
        "    model = model,\n",
        "    optimizer = optimizer,\n",
        "    optimizer_options = optimizer_options,\n",
        "    use_stepLR = use_stepLR,\n",
        "    stepLR_values = stepLR_values,\n",
        "    loss = loss,\n",
        "    metrics = metrics,\n",
        "    epochs = epochs,\n",
        "    train_verbosity = train_verbosity,\n",
        "    cm_plot_labels = cm_plot_labels, \n",
        "    cm_title = cm_title, \n",
        "    layers_to_remove = layers_to_remove, \n",
        "    layers_to_add = layers_to_add,\n",
        "    trainable_layers = trainable_layers,\n",
        "    file_name = file_name\n",
        ")"
      ],
      "id": "EEZ2MK4oC9gd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-92119e0d2a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mlayers_to_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers_to_add\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrainable_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainable_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-3-3ceca7241864>\u001b[0m in \u001b[0;36mfold_validation\u001b[0;34m(origin_path, augment_passed, augment_failed, folder_name, number_augmented_passed, number_augmented_failed, number_of_folds, batch_size, zoom_percentage, save_format, save_prefix, model, optimizer, optimizer_options, use_stepLR, stepLR_values, loss, metrics, epochs, train_verbosity, cm_plot_labels, cm_title, layers_to_remove, layers_to_add, trainable_layers, file_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;31m#Now we create two arrays (one for image names and the other for the scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m   \u001b[0mtotal_image_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_image_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;31m#Now let's store the parameters used on a folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-61f56784fcec>\u001b[0m in \u001b[0;36mcreate_image_arrays\u001b[0;34m(origin_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mpath_passed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs_passed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_passed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{origin_path}/passed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mpath_failed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs_failed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles_failed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{origin_path}/failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    }
  ]
}